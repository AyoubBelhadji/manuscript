\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces A set $\{x_1, x_{2}, x_{3}, x_{4}\}$ can be identified with the atomic measure $\DOTSB \sum@ \slimits@ \limits _{n =1}^{4}\delta _{x_n}$. \relax }}{12}{figure.caption.10}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Three realizations from the CUE with $N = 15$ particles (top) compared to 15 particles sampled i.i.d in the unit circle (bottom). \relax }}{25}{figure.caption.16}
\contentsline {figure}{\numberline {2.3}{\ignorespaces A realization of the Ginibre ensemble with $N = 100$ (left), $N = 200$ (middle) and $N = 500$ (right). The histogram of the radii $|z|$ of 1000 realization of the Ginibre ensemble compared to the theoretical density $f_{N}$, with $N = 100$ particles (left) $N = 200$ particles (middle) and $N = 500$ particles (right). \relax }}{26}{figure.caption.18}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Three realizations from the spherical ensemble with $N = 50$ particles (top) compared to their stereographic projections on the complex plan (bottom). \relax }}{28}{figure.caption.20}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Pseudocode of the HKPV algorithm for sampling from a projection DPP of marginal kernel $\kappa $.\relax }}{30}{figure.caption.23}
\contentsline {figure}{\numberline {2.6}{\ignorespaces The sharpness of Bernstein inequality for bounding the density $f_{\kappa ,1}$. \relax }}{32}{figure.caption.25}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Pseudocode for sampling from a DPP of marginal kernel $\bm {K}$.\relax }}{47}{figure.caption.36}
\contentsline {figure}{\numberline {3.2}{\ignorespaces A graphical depiction of the sampling algorithms for volume sampling (VS) and the DPP with marginal kernel $\bm {V}^{}_{k}\bm {V}_{k}^{\Tran }$. (a) Both algorithms start with an SVD. (b) In Step 1, VS randomly selects $k$ rows of $\bm {V}^{\Tran }$, while our DPP always picks the first $k$ rows. Step 2 is the same for both algorithms: jointly sample $k$ columns of the subsampled $\bm {V}^{\Tran }$, proportionally to their squared volume. Finally, Step 3 is simply the extraction of the corresponding columns of $\bm {X}$. \relax }}{48}{figure.caption.37}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {SVD of $\bm {X}$}}}{48}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Sampling $k$ columns according to VS and our DPP}}}{48}{subfigure.2.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces The pseudocode of the algorithm generating a matrix $\bm {X}$ with prescribed profile of $k$-leverage scores.\relax }}{54}{figure.caption.40}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the sparsity level $p$. \relax }}{56}{figure.caption.42}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {proj}}$, $k=3$}}}{56}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {$\bm {\Sigma }_{5,\text {proj}}$, $k=5$}}}{56}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$, $k=3$}}}{56}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$, $k=5$}}}{56}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {$\bm {\Sigma }_{\text {identity}}$, $k=3$}}}{56}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {$\bm {\Sigma }_{\text {identity}}$, $k=5$}}}{56}{subfigure.4.6}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the effective sparsity level $p_{\mathrm {eff}}(2)$. \relax }}{57}{figure.caption.43}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$}}}{57}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$}}}{57}{subfigure.5.2}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Realizations and bounds for the avoiding probability $\Prb (S \cap T_{p_{\mathrm {eff}}(\theta )} = \emptyset )$ in Theorem\nobreakspace {}\ref {prop:p_eff_proposition} as a function of $\theta $. \relax }}{57}{figure.caption.44}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$}}}{57}{subfigure.6.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$}}}{57}{subfigure.6.2}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the sparsity level $p$ in the case $\beta >1$. \relax }}{58}{figure.caption.45}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\mathaccentV {hat}05E{\bm {\Sigma }}_{3,\text {smooth}}$, $k=3$}}}{58}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\mathaccentV {hat}05E{\bm {\Sigma }}_{3,\text {proj}}$, $k=3$}}}{58}{subfigure.7.2}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Comparison of several column subset selection algorithms for two datasets \leavevmode {\color {darkgreen}with different leverage score profiles}: Basehock and Colon.\relax }}{60}{figure.caption.47}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Basehock (k=10).}}}{60}{subfigure.8.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Colon (k=10).}}}{60}{subfigure.8.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Basehock (k=10).}}}{60}{subfigure.8.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Colon (k=10).}}}{60}{subfigure.8.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Basehock (k=10).}}}{60}{subfigure.8.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Colon (k=10).}}}{60}{subfigure.8.6}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparison of several column subset selection algorithms for two datasets \leavevmode {\color {darkgreen}with different leverage score profiles}: Relathe and Leukemia. \relax }}{62}{figure.caption.48}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Relathe (k=10).}}}{62}{subfigure.9.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Leukemia (k=10).}}}{62}{subfigure.9.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Relathe (k=10).}}}{62}{subfigure.9.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Leukemia (k=10).}}}{62}{subfigure.9.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Relathe (k=10).}}}{62}{subfigure.9.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Leukemia (k=10).}}}{62}{subfigure.9.6}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Comparison of several column subset selection algorithms for the datasets Basehock and Colon on a regression task. \relax }}{63}{figure.caption.51}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{1}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{63}{subfigure.10.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{1}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{63}{subfigure.10.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{2}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{63}{subfigure.10.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{2}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{63}{subfigure.10.4}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Comparison of several column subset selection algorithms for the dataset Colon on a regression task. \relax }}{65}{figure.caption.53}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {z}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$\IeC {\nobreakspace }as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP, OMP and PCR on the dataset Colon.}}}{65}{subfigure.11.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {z}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP, OMP and PCR on the dataset Basehock.}}}{65}{subfigure.11.2}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Comparison of several column subset selection algorithms for the datasets Colon and Basehock. \relax }}{66}{figure.caption.55}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{66}{subfigure.12.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{66}{subfigure.12.2}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Illustration of the interlacing of $\bm {u}$ on $\bm {v}$.\relax }}{83}{figure.caption.61}
\contentsline {figure}{\numberline {3.14}{\ignorespaces The pseudocode of the algorithm proposed by \cite {DhHeSuTr05} for generating a matrix given its leverage scores and spectrum by successively applying Givens rotations.\relax }}{84}{figure.caption.62}
\contentsline {figure}{\numberline {3.15}{\ignorespaces The output of the algorithm in Figure\nobreakspace {}\ref {f:Algo_Givens} for $k=2, \tmspace +\medmuskip {.2222em} d = 10$, $\bm {\sigma } = (1,1)$, and three different values of $\bm {\ell }$ that each add to $k$. Each red dot has coordinates a column of $\bm {F}$. The blue circles have for radii the prescribed $(\sqrt {\ell _i})$. \relax }}{85}{figure.caption.63}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{85}{subfigure.15.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{85}{subfigure.15.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{85}{subfigure.15.3}
\contentsline {figure}{\numberline {3.16}{\ignorespaces The output of our algorithm for $k=2, \tmspace +\medmuskip {.2222em} d = 10$, an input $\bm {\sigma } = (1,1)$, and $\ell $ as in Figure\nobreakspace {}\ref {f:highly_structured_matrix:a}. Each red dot has coordinates a column of $\bm {F}$. The blue circles have for radii the prescribed $(\sqrt {\ell _i})$. \relax }}{86}{figure.caption.64}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{86}{subfigure.16.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{86}{subfigure.16.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{86}{subfigure.16.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{86}{subfigure.16.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{86}{subfigure.16.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{86}{subfigure.16.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{86}{subfigure.16.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{86}{subfigure.16.8}
\contentsline {figure}{\numberline {3.17}{\ignorespaces The interlacing relationships \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:GT_polytope_equations}\unskip \@@italiccorr )}} satisfied by the outer eigensteps of a frame. Thick triangles are used in place of $\leq $ for improved readability.\relax }}{86}{figure.caption.65}
\contentsline {figure}{\numberline {3.18}{\ignorespaces The pseudocode of the generator of random valid eigensteps taking as input $(\bm {\ell },\bm {\sigma })$.\relax }}{88}{figure.caption.66}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The histogram of the eigenvalues of $\mathaccentV {tilde}07E{J}_{N}$ based on 50000 realizations compared to the first intensity function $f_{N}$ of the projection DPP and the eigenvalues of $J_{N}$, with $N \in \{5,10\}$. \relax }}{93}{figure.caption.69}
\contentsline {figure}{\numberline {4.2}{\ignorespaces The local discrapancy of a configuration $\bm {x}$ depends on the set $[\bm {0},u]$. \relax }}{95}{figure.caption.73}
\contentsline {figure}{\numberline {4.3}{\ignorespaces The local discrepancy $\Delta _{\bm {x}}$ for two designs: in the top panel, the Halton sequence with $N \in \{9,25,144\}$; in the bottom panel, the uniform grid with $N \in \{9,25,144\}$. \relax }}{98}{figure.caption.75}
\contentsline {figure}{\numberline {4.4}{\ignorespaces The evaluation of the kernel translate $x \DOTSB \mapstochar \rightarrow k_{s}(0.3,x)$ for $s \in \{1,2,3\}$. \relax }}{105}{figure.caption.80}
\contentsline {figure}{\numberline {4.5}{\ignorespaces The RKHS $\F $ is an ellipsoid in $\mathbb {L}_{2}(\mathrm {d}\omega )$. \relax }}{107}{figure.caption.81}
\contentsline {figure}{\numberline {4.6}{\ignorespaces $\mu _{g}$ in the periodic Sobolev space for three different $g$. \relax }}{110}{figure.caption.84}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Illustration of the largest principal angle between the subspaces $\mathcal {T}(\bm {x})$ and $\mathcal {E}_{N}^{\mathcal {F}}$ in the case of the periodic Sobolev space of order 1. \relax }}{116}{figure.caption.88}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Squared approximation error vs. number of nodes $N$ in the case of the periodic Sobolev space for $s = 1$ (left) and $s=3$ (right). \relax }}{119}{figure.caption.90}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the periodic Sobolev space for $s = 1$ (left) and $s=3$ (right). \relax }}{120}{figure.caption.92}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{6}$ error vs. number of nodes $N$ for $s = 1$ (left) and $s=3$ (right). \relax }}{121}{figure.caption.94}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{7}$ error vs. number of nodes $N$ for $s = 1$ (left) and $s=3$ (right). \relax }}{121}{figure.caption.95}
\contentsline {figure}{\numberline {4.12}{\ignorespaces Squared approximation error vs. number of nodes $N$ in the case of the Korobov space for $s = 1$ (left) and $s=3$ (right); and for $d =2$ (top) and $d=3$ (bottom). \relax }}{124}{figure.caption.97}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the Korobov space for $s = 1$ (left) and $s=3$ (right) under DPPKQ (top), LVSQ (middle) and UGKQ (bottom). \relax }}{125}{figure.caption.99}
\contentsline {figure}{\numberline {4.14}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{4}$ error vs. number of nodes $N$ in the Korobov space for $d=2$ and $s = 1$ (left) and $s=3$ (right). \relax }}{126}{figure.caption.101}
\contentsline {figure}{\numberline {4.15}{\ignorespaces Squared error vs. number of nodes $N$ for various kernels. \relax }}{127}{figure.caption.102}
\contentsline {figure}{\numberline {4.16}{\ignorespaces The squared error for the Gaussian space ($d \in \{2,3\}$, $\gamma =1$). \relax }}{127}{figure.caption.103}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
