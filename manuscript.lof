\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces .... \relax }}{7}{figure.caption.1}
\contentsline {figure}{\numberline {1.2}{\ignorespaces .... \relax }}{10}{figure.caption.3}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the periodic Sobolev space of order $s=3$. \relax }}{11}{figure.caption.5}
\contentsline {figure}{\numberline {1.4}{\ignorespaces .... \relax }}{12}{figure.caption.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces A set $\{x_1, x_{2}, x_{3}, x_{4}\}$ can be identified with the atomic measure $\DOTSB \sum@ \slimits@ \limits _{n =1}^{4}\delta _{x_n}$. \relax }}{14}{figure.caption.11}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Three realizations from the CUE with $N = 15$ particles (top) compared to 15 particles sampled i.i.d in the unit circle (bottom). \relax }}{27}{figure.caption.17}
\contentsline {figure}{\numberline {2.3}{\ignorespaces A realization of the Ginibre ensemble with $N = 100$ (left), $N = 200$ (middle) and $N = 500$ (right). The histogram of the radii $|z|$ of 1000 realization of the Ginibre ensemble compared to the theoretical density $f_{N}$, with $N = 100$ particles (left) $N = 200$ particles (middle) and $N = 500$ particles (right). \relax }}{28}{figure.caption.19}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Three realizations from the spherical ensemble with $N = 50$ particles (top) compared to their stereographic projections on the complex plan (bottom). \relax }}{30}{figure.caption.21}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Pseudocode of the HKPV algorithm for sampling from a projection DPP of marginal kernel $\kappa $.\relax }}{32}{figure.caption.24}
\contentsline {figure}{\numberline {2.6}{\ignorespaces The sharpness of Bernstein inequality for bounding the density $f_{\kappa ,1}$. \relax }}{34}{figure.caption.26}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Pseudocode for sampling from a DPP of marginal kernel $\bm {K}$.\relax }}{49}{figure.caption.37}
\contentsline {figure}{\numberline {3.2}{\ignorespaces A graphical depiction of the sampling algorithms for volume sampling (VS) and the DPP with marginal kernel $\bm {V}^{}_{k}\bm {V}_{k}^{\Tran }$. (a) Both algorithms start with an SVD. (b) In Step 1, VS randomly selects $k$ rows of $\bm {V}^{\Tran }$, while our DPP always picks the first $k$ rows. Step 2 is the same for both algorithms: jointly sample $k$ columns of the subsampled $\bm {V}^{\Tran }$, proportionally to their squared volume. Finally, Step 3 is simply the extraction of the corresponding columns of $\bm {X}$. \relax }}{50}{figure.caption.38}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {SVD of $\bm {X}$}}}{50}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Sampling $k$ columns according to VS and our DPP}}}{50}{subfigure.2.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces The pseudocode of the algorithm generating a matrix $\bm {X}$ with prescribed profile of $k$-leverage scores.\relax }}{56}{figure.caption.41}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the sparsity level $p$. \relax }}{58}{figure.caption.43}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {proj}}$, $k=3$}}}{58}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {$\bm {\Sigma }_{5,\text {proj}}$, $k=5$}}}{58}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$, $k=3$}}}{58}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$, $k=5$}}}{58}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {$\bm {\Sigma }_{\text {identity}}$, $k=3$}}}{58}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {$\bm {\Sigma }_{\text {identity}}$, $k=5$}}}{58}{subfigure.4.6}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the effective sparsity level $p_{\mathrm {eff}}(2)$. \relax }}{59}{figure.caption.44}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$}}}{59}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$}}}{59}{subfigure.5.2}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Realizations and bounds for the avoiding probability $\Prb (S \cap T_{p_{\mathrm {eff}}(\theta )} = \emptyset )$ in Theorem\nobreakspace {}\ref {prop:p_eff_proposition} as a function of $\theta $. \relax }}{59}{figure.caption.45}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$}}}{59}{subfigure.6.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$}}}{59}{subfigure.6.2}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the sparsity level $p$ in the case $\beta >1$. \relax }}{60}{figure.caption.46}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\mathaccentV {hat}05E{\bm {\Sigma }}_{3,\text {smooth}}$, $k=3$}}}{60}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\mathaccentV {hat}05E{\bm {\Sigma }}_{3,\text {proj}}$, $k=3$}}}{60}{subfigure.7.2}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Comparison of several column subset selection algorithms for two datasets \leavevmode {\color {darkgreen}with different leverage score profiles}: Basehock and Colon.\relax }}{62}{figure.caption.48}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Basehock (k=10).}}}{62}{subfigure.8.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Colon (k=10).}}}{62}{subfigure.8.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Basehock (k=10).}}}{62}{subfigure.8.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Colon (k=10).}}}{62}{subfigure.8.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Basehock (k=10).}}}{62}{subfigure.8.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Colon (k=10).}}}{62}{subfigure.8.6}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparison of several column subset selection algorithms for two datasets \leavevmode {\color {darkgreen}with different leverage score profiles}: Relathe and Leukemia. \relax }}{64}{figure.caption.49}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Relathe (k=10).}}}{64}{subfigure.9.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Leukemia (k=10).}}}{64}{subfigure.9.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Relathe (k=10).}}}{64}{subfigure.9.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Leukemia (k=10).}}}{64}{subfigure.9.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Relathe (k=10).}}}{64}{subfigure.9.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Leukemia (k=10).}}}{64}{subfigure.9.6}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Comparison of several column subset selection algorithms for the datasets Basehock and Colon on a regression task. \relax }}{65}{figure.caption.52}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{1}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{65}{subfigure.10.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{1}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{65}{subfigure.10.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{2}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{65}{subfigure.10.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{2}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{65}{subfigure.10.4}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Comparison of several column subset selection algorithms for the dataset Colon on a regression task. \relax }}{67}{figure.caption.54}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {z}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$\IeC {\nobreakspace }as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP, OMP and PCR on the dataset Colon.}}}{67}{subfigure.11.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {z}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP, OMP and PCR on the dataset Basehock.}}}{67}{subfigure.11.2}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Comparison of several column subset selection algorithms for the datasets Colon and Basehock. \relax }}{68}{figure.caption.56}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{68}{subfigure.12.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{68}{subfigure.12.2}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Illustration of the interlacing of $\bm {u}$ on $\bm {v}$.\relax }}{85}{figure.caption.62}
\contentsline {figure}{\numberline {3.14}{\ignorespaces The pseudocode of the algorithm proposed by \cite {DhHeSuTr05} for generating a matrix given its leverage scores and spectrum by successively applying Givens rotations.\relax }}{86}{figure.caption.63}
\contentsline {figure}{\numberline {3.15}{\ignorespaces The output of the algorithm in Figure\nobreakspace {}\ref {f:Algo_Givens} for $k=2, \tmspace +\medmuskip {.2222em} d = 10$, $\bm {\sigma } = (1,1)$, and three different values of $\bm {\ell }$ that each add to $k$. Each red dot has coordinates a column of $\bm {F}$. The blue circles have for radii the prescribed $(\sqrt {\ell _i})$. \relax }}{87}{figure.caption.64}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{87}{subfigure.15.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{87}{subfigure.15.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{87}{subfigure.15.3}
\contentsline {figure}{\numberline {3.16}{\ignorespaces The output of our algorithm for $k=2, \tmspace +\medmuskip {.2222em} d = 10$, an input $\bm {\sigma } = (1,1)$, and $\ell $ as in Figure\nobreakspace {}\ref {f:highly_structured_matrix:a}. Each red dot has coordinates a column of $\bm {F}$. The blue circles have for radii the prescribed $(\sqrt {\ell _i})$. \relax }}{88}{figure.caption.65}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{88}{subfigure.16.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{88}{subfigure.16.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{88}{subfigure.16.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{88}{subfigure.16.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{88}{subfigure.16.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{88}{subfigure.16.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{88}{subfigure.16.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{88}{subfigure.16.8}
\contentsline {figure}{\numberline {3.17}{\ignorespaces The interlacing relationships \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:GT_polytope_equations}\unskip \@@italiccorr )}} satisfied by the outer eigensteps of a frame. Thick triangles are used in place of $\leq $ for improved readability.\relax }}{88}{figure.caption.66}
\contentsline {figure}{\numberline {3.18}{\ignorespaces The pseudocode of the generator of random valid eigensteps taking as input $(\bm {\ell },\bm {\sigma })$.\relax }}{90}{figure.caption.67}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The connections between the different fields of numerical integration with DPPs. \relax }}{93}{figure.caption.68}
\contentsline {figure}{\numberline {4.2}{\ignorespaces The histogram of the eigenvalues of $\mathaccentV {tilde}07E{J}_{N}$ based on 50000 realizations compared to the first intensity function $f_{N}$ of the projection DPP and the eigenvalues of $J_{N}$, with $N \in \{5,10\}$. \relax }}{96}{figure.caption.71}
\contentsline {figure}{\numberline {4.3}{\ignorespaces The local discrapancy of a configuration $\bm {x}$ depends on the set $[\bm {0},u]$. \relax }}{99}{figure.caption.75}
\contentsline {figure}{\numberline {4.4}{\ignorespaces The local discrepancy $\Delta _{\bm {x}}$ for two designs: in the top panel, the Halton sequence with $N \in \{9,25,144\}$; in the bottom panel, the uniform grid with $N \in \{9,25,144\}$. \relax }}{100}{figure.caption.76}
\contentsline {figure}{\numberline {4.5}{\ignorespaces The evaluation of the kernel translate $x \DOTSB \mapstochar \rightarrow k_{s}(0.3,x)$ for $s \in \{1,2,3\}$. \relax }}{108}{figure.caption.82}
\contentsline {figure}{\numberline {4.6}{\ignorespaces The RKHS $\F $ is an ellipsoid in $\mathbb {L}_{2}(\mathrm {d}\omega )$. \relax }}{110}{figure.caption.83}
\contentsline {figure}{\numberline {4.7}{\ignorespaces (Left): comparison of $\sigma _{N+1}$ in the Korobov case according to the spectral order and $(\qopname \relax o{log}N)^{2s(d-1)}N^{-2s}$ for $d \in \{2,3,4\}$ and $s=1$, (Right): comparison of $\sigma _{N+1}$ in the Gaussian case according to the spectral order and $\beta ^{d}e^{-\delta d!^{1/d}N^{1/d}}$ for $d \in \{2,3,4\}$ and $\gamma = 1$.\relax }}{113}{figure.caption.86}
\contentsline {figure}{\numberline {4.8}{\ignorespaces $\mu _{g}$ in the periodic Sobolev space for three different $g$. \relax }}{115}{figure.caption.88}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Illustration of the largest principal angle between the subspaces $\mathcal {T}(\bm {x})$ and $\mathcal {E}_{N}^{\mathcal {F}}$ in the case of the periodic Sobolev space of order 1. \relax }}{122}{figure.caption.93}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Squared approximation error vs. number of nodes $N$ in the case of the periodic Sobolev space for $s = 1$ (left) and $s=3$ (right). \relax }}{125}{figure.caption.95}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the periodic Sobolev space for $s = 1$ (left) and $s=3$ (right). \relax }}{126}{figure.caption.97}
\contentsline {figure}{\numberline {4.12}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{6}$ error vs. number of nodes $N$ for $s = 1$ (left) and $s=3$ (right). \relax }}{127}{figure.caption.99}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Squared approximation error vs. number of nodes $N$ in the case of the Korobov space for $s = 1$ (left) and $s=3$ (right); and for $d =2$ (top) and $d=3$ (bottom). \relax }}{128}{figure.caption.101}
\contentsline {figure}{\numberline {4.14}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the Korobov space for $s = 1$ (left) and $s=3$ (right) under DPPKQ (top), LVSQ (middle) and UGKQ (bottom). \relax }}{130}{figure.caption.103}
\contentsline {figure}{\numberline {4.15}{\ignorespaces The squared error $\delimiter "026B30D \mu _{g}-\DOTSB \sum@ \slimits@ \limits _{n \in [N]} w_{n}k(x_{n},.)\delimiter "026B30D _{\mathcal {F}}^{2}$ vs. the number of nodes $N$ for $\gamma = 0.5, a = 0.25$.\relax }}{131}{figure.caption.104}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The case of $g = e_{1}$.}}}{131}{subfigure.15.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The case of $g = e_{5}$.}}}{131}{subfigure.15.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {The case of $g = e_{10}$.}}}{131}{subfigure.15.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {The case of $g = e_{15}$.}}}{131}{subfigure.15.4}
\contentsline {figure}{\numberline {4.16}{\ignorespaces The squared error for the Gaussian space ($d \in \{2,3\}$, $\gamma =1$). \relax }}{131}{figure.caption.105}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
