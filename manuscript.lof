\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Three realizations from the CUE with $N = 15$ particles (top) compared to 15 particles sampled i.i.d in the unit circle (bottom). \relax }}{22}{figure.caption.13}
\contentsline {figure}{\numberline {2.2}{\ignorespaces A realization of the Ginibre ensemble with $N = 100$ (left), $N = 200$ (middle) and $N = 500$ (right). The histogram of the radii $|z|$ of 1000 realization of the Ginibre ensemble compared to the theoretical density $f_{N}$, with $N = 100$ particles (left) $N = 200$ particles (middle) and $N = 500$ particles (right). \relax }}{23}{figure.caption.15}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Three realizations from the spherical ensemble with $N = 50$ particles (top) compared to their stereographic projections on the complex plan (bottom). \relax }}{24}{figure.caption.17}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Pseudocode a sampler of projection DPP based on a random matrix model.\relax }}{25}{figure.caption.19}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Pseudocode of the HKPV algorithm for sampling from a projection DPP of marginal kernel $\KDPP $.\relax }}{26}{figure.caption.21}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Pseudocode for sampling from a DPP of marginal kernel $\bm {K}$.\relax }}{39}{figure.caption.31}
\contentsline {figure}{\numberline {3.2}{\ignorespaces A graphical depiction of the sampling algorithms for volume sampling (VS) and the DPP with marginal kernel $\bm {V}^{}_{k}\bm {V}_{k}^{\Tran }$. (a) Both algorithms start with an SVD. (b) In Step 1, VS randomly selects $k$ rows of $\bm {V}^{\Tran }$, while our DPP always picks the first $k$ rows. Step 2 is the same for both algorithms: jointly sample $k$ columns of the subsampled $\bm {V}^{\Tran }$, proportionally to their squared volume. Finally, Step 3 is simply the extraction of the corresponding columns of $\bm {X}$. \relax }}{40}{figure.caption.32}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {SVD of $\bm {X}$}}}{40}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Sampling $k$ columns according to VS and our DPP}}}{40}{subfigure.2.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces The pseudocode of the algorithm generating a matrix $\bm {X}$ with prescribed profile of $k$-leverage scores.\relax }}{46}{figure.caption.35}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the sparsity level $p$. \relax }}{48}{figure.caption.37}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {proj}}$, $k=3$}}}{48}{subfigure.4.1}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {$\bm {\Sigma }_{5,\text {proj}}$, $k=5$}}}{48}{subfigure.4.4}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$, $k=3$}}}{48}{subfigure.4.2}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$, $k=5$}}}{48}{subfigure.4.5}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {$\bm {\Sigma }_{\text {identity}}$, $k=3$}}}{48}{subfigure.4.3}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {$\bm {\Sigma }_{\text {identity}}$, $k=5$}}}{48}{subfigure.4.6}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the effective sparsity level $p_{\mathrm {eff}}(2)$. \relax }}{49}{figure.caption.38}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$}}}{49}{subfigure.5.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$}}}{49}{subfigure.5.2}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Realizations and bounds for the avoiding probability $\Prb (S \cap T_{p_{\mathrm {eff}}(\theta )} = \emptyset )$ in Theorem\nobreakspace {}\ref {prop:p_eff_proposition} as a function of $\theta $. \relax }}{49}{figure.caption.39}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\bm {\Sigma }_{3,\text {smooth}}$}}}{49}{subfigure.6.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\bm {\Sigma }_{5,\text {smooth}}$}}}{49}{subfigure.6.2}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Realizations and bounds for $\mathbb {E} \delimiter "026B30D \bm {X}- \Pi _{S}^{\Fr } \bm {X}\delimiter "026B30D _{\Fr }^{2}$ as a function of the sparsity level $p$ in the case $\beta >1$. \relax }}{50}{figure.caption.40}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\mathaccentV {hat}05E{\bm {\Sigma }}_{3,\text {smooth}}$, $k=3$}}}{50}{subfigure.7.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\mathaccentV {hat}05E{\bm {\Sigma }}_{3,\text {proj}}$, $k=3$}}}{50}{subfigure.7.2}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Comparison of several column subset selection algorithms for two datasets \leavevmode {\color {darkgreen}with different leverage score profiles}: Basehock and Colon.\relax }}{52}{figure.caption.42}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Basehock (k=10).}}}{52}{subfigure.8.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Colon (k=10).}}}{52}{subfigure.8.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Basehock (k=10).}}}{52}{subfigure.8.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Colon (k=10).}}}{52}{subfigure.8.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Basehock (k=10).}}}{52}{subfigure.8.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Colon (k=10).}}}{52}{subfigure.8.6}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparison of several column subset selection algorithms for two datasets \leavevmode {\color {darkgreen}with different leverage score profiles}: Relathe and Leukemia. \relax }}{54}{figure.caption.43}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Relathe (k=10).}}}{54}{subfigure.9.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$k$-leverage scores profile and cumulative profile for the dataset Leukemia (k=10).}}}{54}{subfigure.9.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Relathe (k=10).}}}{54}{subfigure.9.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the five algorithms on the dataset Leukemia (k=10).}}}{54}{subfigure.9.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Relathe (k=10).}}}{54}{subfigure.9.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {Boxplots of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ on a batch of 50 samples for the boosting of randomized algorithms on the dataset Leukemia (k=10).}}}{54}{subfigure.9.6}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Comparison of several column subset selection algorithms for the datasets Basehock and Colon on a regression task. \relax }}{55}{figure.caption.46}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{1}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{55}{subfigure.10.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{1}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{55}{subfigure.10.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{2}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{55}{subfigure.10.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {y}_{2}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{55}{subfigure.10.4}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Comparison of several column subset selection algorithms for the dataset Colon on a regression task. \relax }}{57}{figure.caption.48}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {z}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$\IeC {\nobreakspace }as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP, OMP and PCR on the dataset Colon.}}}{57}{subfigure.11.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \mathbf {z}-\bm {X}\mathaccentV {hat}05E{\bm {w}}_S\delimiter "026B30D _{2}$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP, OMP and PCR on the dataset Basehock.}}}{57}{subfigure.11.2}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Comparison of several column subset selection algorithms for the datasets Colon and Basehock. \relax }}{58}{figure.caption.50}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {The value of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Colon.}}}{58}{subfigure.12.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {The value of $\delimiter "026B30D \bm {X}-\Pi _{S}^{\Fr }\bm {X}\delimiter "026B30D _{\Fr }$ as a function of $k$ on a batch of 50 samples for the algorithms: DPP, VS, DP and PCR on the dataset Basehock.}}}{58}{subfigure.12.2}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Illustration of the interlacing of $\bm {u}$ on $\bm {v}$.\relax }}{64}{figure.caption.51}
\contentsline {figure}{\numberline {3.14}{\ignorespaces The pseudocode of the algorithm proposed by \cite {DhHeSuTr05} for generating a matrix given its leverage scores and spectrum by successively applying Givens rotations.\relax }}{66}{figure.caption.52}
\contentsline {figure}{\numberline {3.15}{\ignorespaces The output of the algorithm in Figure\nobreakspace {}\ref {f:Algo_Givens} for $k=2, \tmspace +\medmuskip {.2222em} d = 10$, $\bm {\sigma } = (1,1)$, and three different values of $\bm {\ell }$ that each add to $k$. Each red dot has coordinates a column of $\bm {F}$. The blue circles have for radii the prescribed $(\sqrt {\ell _i})$. \relax }}{67}{figure.caption.53}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{67}{subfigure.15.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{67}{subfigure.15.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{67}{subfigure.15.3}
\contentsline {figure}{\numberline {3.16}{\ignorespaces The output of our algorithm for $k=2, \tmspace +\medmuskip {.2222em} d = 10$, an input $\bm {\sigma } = (1,1)$, and $\ell $ as in Figure\nobreakspace {}\ref {f:highly_structured_matrix:a}. Each red dot has coordinates a column of $\bm {F}$. The blue circles have for radii the prescribed $(\sqrt {\ell _i})$. \relax }}{67}{figure.caption.54}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{67}{subfigure.16.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{67}{subfigure.16.2}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{67}{subfigure.16.3}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{67}{subfigure.16.4}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{67}{subfigure.16.5}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{67}{subfigure.16.6}
\contentsline {subfigure}{\numberline {(g)}{\ignorespaces {}}}{67}{subfigure.16.7}
\contentsline {subfigure}{\numberline {(h)}{\ignorespaces {}}}{67}{subfigure.16.8}
\contentsline {figure}{\numberline {3.17}{\ignorespaces The interlacing relationships \textup {\hbox {\mathsurround \z@ \normalfont (\ignorespaces \ref {eq:GT_polytope_equations}\unskip \@@italiccorr )}} satisfied by the outer eigensteps of a frame. Thick triangles are used in place of $\leq $ for improved readability.\relax }}{68}{figure.caption.55}
\contentsline {figure}{\numberline {3.18}{\ignorespaces The pseudocode of the generator of random valid eigensteps taking as input $(\bm {\ell },\bm {\sigma })$.\relax }}{70}{figure.caption.56}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The local discrapancy of a configuration $\bm {x}$ depends on the set $[\bm {0},u]$. \relax }}{76}{figure.caption.61}
\contentsline {figure}{\numberline {4.2}{\ignorespaces The local discrepancy $\Delta _{\bm {x}}$ for two designs: in the top panel, the Halton sequence with $N \in \{9,25,144\}$; in the bottom panel, the uniform grid with $N \in \{9,25,144\}$. \relax }}{79}{figure.caption.63}
\contentsline {figure}{\numberline {4.3}{\ignorespaces The evaluation of the kernel $k_{s}$ for $s \in \{1,2,3,4,5\}$. \relax }}{85}{figure.caption.68}
\contentsline {figure}{\numberline {4.4}{\ignorespaces The RKHS $\F $ is an ellipsoid in $\mathbb {L}_{2}(\mathrm {d}\omega )$. \relax }}{88}{figure.caption.71}
\contentsline {figure}{\numberline {4.5}{\ignorespaces $\mu _{g}$ in the periodic Sobolev space for three different $g$. \relax }}{90}{figure.caption.72}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Illustration of the largest principal angle between the subspaces $\mathcal {T}(\bm {x})$ and $\mathcal {E}_{N}^{\mathcal {F}}$ in the case of the periodic Sobolev space of order 1. \relax }}{96}{figure.caption.76}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Squared approximation error vs. number of nodes $N$ in the case of the periodic Sobolev space for $s = 1$ (left) and $s=3$ (right). \relax }}{99}{figure.caption.78}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the periodic Sobolev space for $s = 1$ (left) and $s=3$ (right). \relax }}{100}{figure.caption.80}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{6}$ error vs. number of nodes $N$ for $s = 1$ (left) and $s=3$ (right). \relax }}{101}{figure.caption.82}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{7}$ error vs. number of nodes $N$ for $s = 1$ (left) and $s=3$ (right). \relax }}{101}{figure.caption.83}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Squared approximation error vs. number of nodes $N$ in the case of the Korobov space for $s = 1$ (left) and $s=3$ (right); and for $d =2$ (top) and $d=3$ (bottom). \relax }}{104}{figure.caption.85}
\contentsline {figure}{\numberline {4.12}{\ignorespaces Squared interpolation error for the embedding of the eigenfunctions vs. number of nodes $N$ in the Korobov space for $s = 1$ (left) and $s=3$ (right) under DPPKQ (top), LVSQ (middle) and UGKQ (bottom). \relax }}{105}{figure.caption.87}
\contentsline {figure}{\numberline {4.13}{\ignorespaces Squared worst interpolation error on $\mathcal {G}_{4}$ error vs. number of nodes $N$ in the Korobov space for $d=2$ and $s = 1$ (left) and $s=3$ (right). \relax }}{106}{figure.caption.89}
\contentsline {figure}{\numberline {4.14}{\ignorespaces Squared error vs. number of nodes $N$ for various kernels. \relax }}{107}{figure.caption.90}
\contentsline {figure}{\numberline {4.15}{\ignorespaces The squared error for the Gaussian space ($d \in \{2,3\}$, $\gamma =1$). \relax }}{107}{figure.caption.91}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
